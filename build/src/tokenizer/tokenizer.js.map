{"version":3,"file":"tokenizer.js","sourceRoot":"","sources":["../../../src/tokenizer/tokenizer.ts"],"names":[],"mappings":";;AAAA,2CAA8B;AAC9B,yDAAyE;AAEzE,2CAA+C;AAC/C,iCAA4B;AAC5B,qCAAsD;AAKtD,MAAa,SAAS;IA0BpB,YACI,QAAqB,EACrB,UAA2B,SAAS,CAAC,eAAe,EAAE,SAAS,GAAG,KAAK;QA3B3E,cAAS,GAAG,IAAI,CAAC;QAOjB,mBAAmB;QACnB,SAAI,GAAG,CAAC,CAAC;QAET,UAAK,GAAa,EAAE,CAAC;QACrB,SAAI,GAAU,EAAE,CAAC;QAEjB,gBAAW,GAAe,EAAE,CAAC;QAC7B,iBAAY,GAAa,EAAE,CAAC;QAE5B,eAAU,GAA6B,EAAE,CAAC;QAC1C,oBAAe,GAA6B,EAAE,CAAC;QAE/C,aAAQ,GAA2B,EAAE,CAAC;QAEtC,aAAQ,GAAgB,IAAI,GAAG,EAAU,CAAC;QAE1C,sBAAiB,GAAG,IAAI,GAAG,EAAQ,CAAC;QA+BpC,sCAAsC;QACtC,aAAQ,GAAG,CAAC,IAAY,EACb,EAAE;YACP,OAAO,eAAE,CAAC,IAAI,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;QAC7B,CAAC,CAAA;QAEL,sCAAsC;QACtC,eAAU,GAAG,CAAC,IAAY,EACf,EAAE;YACP,IAAI,IAAI,IAAI,IAAI,CAAC,UAAU,EAAE;gBAC3B,OAAO,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;aAC9B;iBAAM;gBACL,OAAO,UAAU,IAAI,KAAK,CAAC;aAC5B;QACH,CAAC,CAAA;QAEL,eAAU,GACN,CAAC,IAAU,EAAE,EAAE;YACb,OAAO,SAAS,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,YAAY,IAAI,CAAC,KAAK,YACxD,IAAI,CAAC,MAAM,GAAG,CAAC;QACrB,CAAC,CAAA;QAEL,cAAS,GACL,CAAC,GAAQ,EAAE,EAAE;YACX,OAAO,QAAQ,GAAG,EAAE,CAAC;QACvB,CAAC,CAAA;QAEL,gBAAW,GACP,CAAC,KAAe,EAAE,IAAY,EAAE,EAAE;YAChC,IAAI,SAAS,GAAG,CAAC,CAAC;YAClB,MAAM,SAAS,GAAa,EAAE,CAAC;YAC/B,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,EAAE;gBACpB,IAAI,IAAI,CAAC,KAAK,GAAG,CAAC,EAAE;oBAClB,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;iBACpC;gBACD,2CAA2C;qBACtC;oBACH,MAAM,IAAI,GAAG,IACT,KAAK,CAAC,KAAK,CAAC,SAAS,EAAE,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC;oBACjE,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBACrB,SAAS,IAAI,IAAI,CAAC,MAAM,CAAC;iBAC1B;YACH,CAAC,CAAC,CAAC;YACH,OAAO,SAAS,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC7B,CAAC,CAAA;QAEL,mBAAc,GACV,CAAC,KAAe,EAAE,IAAY,EAAE,SAAiC,EAAE,EAAE;YACnE,IAAI,SAAS,GAAG,CAAC,CAAC;YAClB,MAAM,SAAS,GAAa,EAAE,CAAC;YAC/B,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,EAAE;gBACpB,IAAI,IAAI,CAAC,KAAK,GAAG,CAAC,EAAE;oBAClB,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;iBACpC;gBACD,2CAA2C;qBACtC;oBACH,yDAAyD;oBACzD,kBAAkB;oBAClB,MAAM,IAAI,GAAG,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC;oBAC9C,MAAM,IAAI,GAAG,IAAI,IAAI,GAAG,CAAC;oBACzB,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBACrB,SAAS,IAAI,IAAI,CAAC,MAAM,CAAC;iBAC1B;YACH,CAAC,CAAC,CAAC;YACH,OAAO,SAAS,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC7B,CAAC,CAAA;QAEL,oBAAe,GACX,CACI,KAAe,EAAE,IAAY,EAAE,YAA6B,EAAE,EAAE;YAClE,IAAI,SAAS,GAAG,CAAC,CAAC;YAClB,MAAM,MAAM,GAAY,EAAE,CAAC;YAC3B,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,KAAK,EAAE,EAAE;gBAC3B,IAAI,IAAI,CAAC,KAAK,GAAG,CAAC,EAAE;oBAClB,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC;wBACnB,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,IAAI,KAAK,gBAAO,EAAE;wBAC9C,MAAM,CAAC,IAAI,CAAC,EAAC,IAAI,EAAE,gBAAO,EAAE,IAAI,EAAE,KAAK,CAAC,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;qBACxD;yBAAM;wBACL,MAAM,IAAI,GACN,GAAG,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,IAAI,IAAI,KAAK,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC;wBAC9D,MAAM,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,EAAC,IAAI,EAAE,gBAAO,EAAE,IAAI,EAAC,CAAC;qBACnD;iBACF;qBAAM;oBACL,MAAM,IAAI,GACN,KAAK,CAAC,KAAK,CAAC,SAAS,EAAE,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;oBAC9D,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;oBACvD,SAAS,IAAI,IAAI,CAAC,MAAM,CAAC;iBAC1B;YACH,CAAC,CAAC,CAAC;YACH,OAAO,MAAM,CAAC;QAChB,CAAC,CAAA;QApHH,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;QACzB,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC;QACxB,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,EAAE;YAC7B,MAAM,IAAI,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;YAChD,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;QACnC,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;IAC7B,CAAC;IA8GD,2BAA2B;IAC3B,2BAA2B;IAE3B,2EAA2E;IAC3E,EAAE;IACF,oBAAoB;IACpB,EAAE;IACF,2EAA2E;IAC3E,OAAO,CAAC,GAAQ,EAAE,IAAY;QAC5B,oEAAoE;QACpE,uEAAuE;QACvE,iBAAiB;QACjB,MAAM,EAAE,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC;QAC7B,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QACtB,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAEpB,4CAA4C;QAC5C,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;QAE9B,MAAM,OAAO,GAAG,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QACzC,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;QAE1C,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QAC1C,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QAE9B,MAAM,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,KAAK,EAAE,EAAE;YAC7B,oEAAoE;YACpE,IAAI,CAAC,CAAC,IAAI,IAAI,IAAI,CAAC,UAAU,CAAC,EAAE;gBAC9B,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC;aACxC;YAED,wBAAwB;YACxB,kEAAkE;YAClE,IAAI,IAAI,IAAI,IAAI,CAAC,eAAe,EAAE;gBAChC,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,EAAE,CAAC;aAC9B;iBAAM;gBACL,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;aAChC;YAED,kDAAkD;YAClD,8BAA8B;YAC9B,IAAI,IAAI,IAAI,IAAI,CAAC,QAAQ,EAAE;gBACzB,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;aAC9B;iBAAM;gBACL,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC;aAC5B;QACH,CAAC,CAAC,CAAC;QAEH,oBAAoB;IACtB,CAAC;IAED,2EAA2E;IAC3E,EAAE;IACF,mCAAmC;IACnC,EAAE;IACF,2EAA2E;IAE3E,2EAA2E;IAC3E,EAAE;IACF,oDAAoD;IACpD,EAAE;IACF,2EAA2E;IAC3E,WAAW,CAAC,KAAa,EAAE,MAAc;QACvC,MAAM,CAAC,GAAG,IAAI,GAAG,CAAC,KAAK,CAAC,CAAC;QACzB,MAAM,CAAC,GAAG,IAAI,GAAG,CAAC,MAAM,CAAC,CAAC;QAC1B,OAAO,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/C,CAAC;IAED,cAAc,CAAC,WAAsB;QACnC,OAAO,IAAI,GAAG,CAAC,CAAC,GAAG,WAAW,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC9E,CAAC;IAED,KAAK,CAAC,KAAe,EAAE,MAAgB;QACrC,MAAM,EAAC,KAAK,EAAE,IAAI,EAAE,SAAS,EAAE,UAAU,EAAE,MAAM,EAAC,GAAG,WAAI,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;QAEzE,yDAAyD;QACzD,MAAM,WAAW,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,KAAK,CAAC,MAAM,GAAG,IAAI,CAAC,CAAC;QAEzD,uEAAuE;QACvE,MAAM,YAAY,GAAG,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;QAC3C,gEAAgE;QAChE,kDAAkD;QAClD,4CAA4C;QAE5C,MAAM,cAAc,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,GAAG,SAAS,EAAE,CAAC,CAAC,GAAG,KAAK,CAAC,MAAM,CAAC;QAE5E,MAAM,YAAY,GAAG,UAAU,GAAG,CAAC,CAAC;QAEpC,oEAAoE;QACpE,oEAAoE;QACpE,6DAA6D;QAC7D,8CAA8C;QAC9C,2BAA2B;QAC3B,0CAA0C;QAC1C,EAAE;QACF,0DAA0D;QAC1D,8CAA8C;QAC9C,wBAAwB;QACxB,QAAQ;QACR,aAAa;QACb,4BAA4B;QAC5B,QAAQ;QACR,SAAS;QACT,wDAAwD;QACxD,MAAM,WAAW,GAAG,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;QACpD,MAAM,cAAc,GAAG,IAAI,CAAC,cAAc,CAAC,WAAW,CAAC,CAAC;QAExD,IAAI,KAAK,GAAG,WAAW,GAAG,YAAY,GAAG,cAAc,GAAG,YAAY,CAAC;QACvE,+BAA+B;QAC/B,kBAAkB;QAClB,IAAI;QAEJ,4EAA4E;QAC5E,4EAA4E;QAC5E,sEAAsE;QACtE,yEAAyE;QACzE,MAAM,aAAa,GACf,CAAC,WAAW,CAAC,IAAI,GAAG,cAAc,CAAC,IAAI,CAAC,GAAG,WAAW,CAAC,IAAI,CAAC;QAChE,IAAI,WAAW,CAAC,IAAI,KAAK,cAAc,CAAC,IAAI;YACxC,WAAW,CAAC,IAAI,KAAK,MAAM,CAAC,MAAM,EAAE;YACtC,KAAK,GAAG,CAAC,CAAC,CAAC;SACZ;QAED,uBAAuB;QACvB,kBAAkB;QAClB,IAAI;QACJ,IAAI,KAAK,IAAI,IAAI,EAAE;YACjB,KAAK,GAAG,CAAC,CAAC,CAAC;SACZ;QAED,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,MAAM,SAAS,GAAG,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YACvD,MAAM,UAAU,GAAG,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YACzD,MAAM,SAAS,GAAG,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;YACvD,OAAO,CAAC,GAAG,CACP,eAAe,KAAK,OAAO,WAAW,QAAQ,YAAY,QACtD,cAAc,QAAQ,YAAY,QAAQ,aAAa,EAAE,CAAC,CAAC;YACnE,OAAO,CAAC,GAAG,CAAC,gBAAgB,KAAK,CAAC,MAAM,UAAU,IAAI,UAClD,SAAS,WAAW,UAAU,EAAE,CAAC,CAAC;YACtC,OAAO,CAAC,GAAG,CAAC,gBAAgB,SAAS,GAAG,CAAC,CAAC;YAC1C,OAAO,CAAC,GAAG,CAAC,iBAAiB,UAAU,GAAG,CAAC,CAAC;YAC5C,OAAO,CAAC,GAAG,CAAC,gBAAgB,SAAS,GAAG,CAAC,CAAC;YAC1C,OAAO,CAAC,GAAG,CAAC,gBAAgB,KAAK,GAAG,CAAC,CAAC;YACtC,OAAO,CAAC,GAAG,CAAC,iBAAiB,MAAM,GAAG,CAAC,CAAC;YACxC,OAAO,CAAC,GAAG,CAAC,gBAAgB,KAAK,GAAG,CAAC,CAAC;YACtC,OAAO,CAAC,GAAG,EAAE,CAAC;SACf;QAED,OAAO,EAAC,KAAK,EAAE,MAAM,EAAE,UAAU,GAAG,CAAC,EAAC,CAAC;IACzC,CAAC;IAED,8BAA8B;IAC9B,mDAAmD;IACnD,YAAY,CAAC,KAAa;QACxB,MAAM,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;QAC/B,MAAM,OAAO,GAAG,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QACzC,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QAE1C,yEAAyE;QACzE,MAAM,SAAS,GAAa,EAAE,CAAC;QAC/B,MAAM,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,KAAK,EAAE,EAAE;YAC7B,0DAA0D;YAE1D,IAAI,IAAI,IAAI,IAAI,CAAC,QAAQ,EAAE;gBACzB,mDAAmD;gBACnD,IAAI,IAAI,CAAC,SAAS,EAAE;oBAClB,MAAM,WAAW,GAAG,OAAO,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;oBACnD,OAAO,CAAC,GAAG,CAAC,MAAM,WAAW,YAAY,CAAC,CAAC;iBAC5C;gBAED,mDAAmD;gBACnD,mDAAmD;gBACnD,+BAA+B;gBAC/B,MAAM,KAAK,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC;gBAElC,uDAAuD;gBACvD,yBAAyB;gBACzB,MAAM,IAAI,GAAG,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;gBACjC,MAAM,MAAM,GAAG,KAAK,CAAC,GAAG,CACpB,CAAC,IAAI,EAAE,EAAE,CACL,mBAAK,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,CAAC,IAAE,KAAK,EAAE,IAAI,IAAE,CAAC,CAAC;gBAEtE,MAAM,MAAM,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC;gBAExD,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;aACxB;iBAAM;gBACL,IAAI,IAAI,CAAC,SAAS,EAAE;oBAClB,OAAO,CAAC,GAAG,CAAC,MAAM,OAAO,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC;iBAC9C;gBACD,SAAS,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;aACpB;QACH,CAAC,CAAC,CAAC;QAEH,MAAM,IAAI,GAAG,wBAAY,CAAC,SAAS,CAAC,CAAC;QAErC,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC;YAC1B,SAAS,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE,EAAE;gBAC1B,MAAM,IAAI,GAAG,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;gBAClD,0DAA0D;gBAC1D,kCAAkC;gBAClC,OAAO,CAAC,GAAG,CAAC,QAAQ,IAAI,GAAG,CAAC,CAAC;YAC/B,CAAC,CAAC,CAAC;YACH,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC;YAC1B,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,EAAE;gBACpB,OAAO,CAAC,GAAG,CAAC,OAAO,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;YAC9C,CAAC,CAAC,CAAC;SACJ;QAED,OAAO,IAAI,CAAC;IACd,CAAC;;AAlWM,yBAAe,GAAG,8BAAU,CAAC,SAAS,CAAC,CAAC;AAoC/C,2EAA2E;AAC3E,EAAE;AACF,oBAAoB;AACpB,EAAE;AACF,2EAA2E;AAE3E,sCAAsC;AAC/B,yBAAe,GAAG,CAAC,IAAY,EAC3B,EAAE;IACP,wEAAwE;IACxE,IAAI;IACJ,iCAAiC;IACjC,IAAI;IACJ,OAAO,SAAS,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE,CAAC,CAAC;AAC5D,CAAC,CAAA;AArDP,8BAsWC","sourcesContent":["import {v3} from 'murmurhash';\nimport {newStemmer, Stemmer as SnowballStemmer} from 'snowball-stemmers';\n\nimport {Edge, findBestPath} from './best_path';\nimport {diff} from './diff';\nimport {Token, TokenFactory, UNKNOWN} from './tokens';\nimport {HASH, ID, PID} from './types';\n\nexport type StemmerFunction = (term: string) => string;\n\nexport class Tokenizer {\n  debugMode = true;\n\n  static snowballStemmer = newStemmer('english');\n\n  // Function that stems a term.\n  stemTerm: StemmerFunction;\n\n  // Murmurhash seed.\n  seed = 0;\n\n  items: string[] = [];\n  pids: PID[] = [];\n\n  hashedItems: number[][] = [];\n  stemmedItems: string[] = [];\n\n  hashToText: {[hash: number]: string} = {};\n  hashToFrequency: {[hash: number]: number} = {};\n\n  postings: {[hash: number]: ID[]} = {};\n\n  badWords: Set<string> = new Set<string>();\n\n  hashedBadWordsSet = new Set<HASH>();\n\n  constructor(\n      badWords: Set<string>,\n      stemmer: StemmerFunction = Tokenizer.defaultStemTerm, debugMode = false) {\n    this.badWords = badWords;\n    this.stemTerm = stemmer;\n    this.badWords.forEach((term) => {\n      const hash = this.hashTerm(this.stemTerm(term));\n      this.hashedBadWordsSet.add(hash);\n    });\n\n    this.debugMode = debugMode;\n  }\n\n  ///////////////////////////////////////////////////////////////////////////\n  //\n  // Utility functions\n  //\n  ///////////////////////////////////////////////////////////////////////////\n\n  // Arrow function to allow use in map.\n  static defaultStemTerm = (term: string):\n      string => {\n        // if (term.toLowerCase() === 'fries' || term.toLowerCase() === 'fried')\n        // {\n        //     return term.toLowerCase();\n        // }\n        return Tokenizer.snowballStemmer.stem(term.toLowerCase());\n      }\n\n  // Arrow function to allow use in map.\n  hashTerm = (term: string):\n      number => {\n        return v3(term, this.seed);\n      }\n\n  // Arrow function to allow use in map.\n  decodeTerm = (hash: number):\n      string => {\n        if (hash in this.hashToText) {\n          return this.hashToText[hash];\n        } else {\n          return `###HASH${hash}###`;\n        }\n      }\n\n  decodeEdge =\n      (edge: Edge) => {\n        return `Edge(\"${this.items[edge.label]}\", score=${edge.score}, length=${\n            edge.length})`;\n      }\n\n  pidToName =\n      (pid: PID) => {\n        return `ITEM_${pid}`;\n      }\n\n  markMatches =\n      (terms: string[], path: Edge[]) => {\n        let termIndex = 0;\n        const rewritten: string[] = [];\n        path.forEach((edge) => {\n          if (edge.label < 0) {\n            rewritten.push(terms[termIndex++]);\n          }\n          // TODO: EXPERIMENT 1: filter out badwords.\n          else {\n            const text = `[${\n                terms.slice(termIndex, termIndex + edge.length).join(' ')}]`;\n            rewritten.push(text);\n            termIndex += edge.length;\n          }\n        });\n        return rewritten.join(' ');\n      }\n\n  replaceMatches =\n      (terms: string[], path: Edge[], pidToName: ((pid: PID) => string)) => {\n        let termIndex = 0;\n        const rewritten: string[] = [];\n        path.forEach((edge) => {\n          if (edge.label < 0) {\n            rewritten.push(terms[termIndex++]);\n          }\n          // TODO: EXPERIMENT 1: filter out badwords.\n          else {\n            // TODO: Where does toUpperCase and replacing spaces with\n            // underscores go?\n            const name = pidToName(this.pids[edge.label]);\n            const text = `[${name}]`;\n            rewritten.push(text);\n            termIndex += edge.length;\n          }\n        });\n        return rewritten.join(' ');\n      }\n\n  tokenizeMatches =\n      <T extends Token>(\n          terms: string[], path: Edge[], tokenFactory: TokenFactory<T>) => {\n        let termIndex = 0;\n        const tokens: Token[] = [];\n        path.forEach((edge, index) => {\n          if (edge.label < 0) {\n            if (tokens.length === 0 ||\n                tokens[tokens.length - 1].type !== UNKNOWN) {\n              tokens.push({type: UNKNOWN, text: terms[termIndex++]});\n            } else {\n              const text =\n                  `${tokens[tokens.length - 1].text} ${terms[termIndex++]}`;\n              tokens[tokens.length - 1] = {type: UNKNOWN, text};\n            }\n          } else {\n            const text =\n                terms.slice(termIndex, termIndex + edge.length).join(' ');\n            tokens.push(tokenFactory(this.pids[edge.label], text));\n            termIndex += edge.length;\n          }\n        });\n        return tokens;\n      }\n\n  // TODO: printFrequencies()\n  // TODO: printHashedItems()\n\n  ///////////////////////////////////////////////////////////////////////////\n  //\n  // Indexing a phrase\n  //\n  ///////////////////////////////////////////////////////////////////////////\n  addItem(pid: PID, text: string): void {\n    // Internal id for this item. NOTE that the internal id is different\n    // from the pid. The items \"coke\" and \"coca cola\" share a pid, but have\n    // different ids.\n    const id = this.items.length;\n    this.items.push(text);\n    this.pids.push(pid);\n\n    // Split input string into individual terms.\n    const terms = text.split(' ');\n\n    const stemmed = terms.map(this.stemTerm);\n    this.stemmedItems.push(stemmed.join(' '));\n\n    const hashed = stemmed.map(this.hashTerm);\n    this.hashedItems.push(hashed);\n\n    hashed.forEach((hash, index) => {\n      // Add this term to hash_to_text so that we can decode hashes later.\n      if (!(hash in this.hashToText)) {\n        this.hashToText[hash] = stemmed[index];\n      }\n\n      // Update term frequency\n      // DESIGN ALTERNATIVE: could use lengths of posting lists instead.\n      if (hash in this.hashToFrequency) {\n        this.hashToFrequency[hash]++;\n      } else {\n        this.hashToFrequency[hash] = 1;\n      }\n\n      // Add current item to posting list for this term.\n      // This is the inverted index.\n      if (hash in this.postings) {\n        this.postings[hash].push(id);\n      } else {\n        this.postings[hash] = [id];\n      }\n    });\n\n    // TODO: Add tuples.\n  }\n\n  ///////////////////////////////////////////////////////////////////////////\n  //\n  // Indexing all tuples of a phrase.\n  //\n  ///////////////////////////////////////////////////////////////////////////\n\n  ///////////////////////////////////////////////////////////////////////////\n  //\n  // Full-text matching and scoring algorithm follows.\n  //\n  ///////////////////////////////////////////////////////////////////////////\n  commonTerms(query: HASH[], prefix: HASH[]) {\n    const a = new Set(query);\n    const b = new Set(prefix);\n    return new Set([...a].filter(x => b.has(x)));\n  }\n\n  commonBadWords(commonTerms: Set<HASH>) {\n    return new Set([...commonTerms].filter(x => this.hashedBadWordsSet.has(x)));\n  }\n\n  score(query: number[], prefix: number[]) {\n    const {match, cost, leftmostA, rightmostA, common} = diff(query, prefix);\n\n    // Ratio of match length to match length + edit distance.\n    const matchFactor = match.length / (match.length + cost);\n\n    // Ratio of match words common to query and prefix and length of match.\n    const commonFactor = common / match.length;\n    // EXPERIMENT: replace above line with one of the two following:\n    // const commonFactor = common / (rightmostA + 1);\n    // const commonFactor = common / rightmostA;\n\n    const positionFactor = Math.max(match.length - leftmostA, 0) / match.length;\n\n    const lengthFactor = rightmostA + 1;\n\n    // This approach doesn't work because the match can contain trailing\n    // garbage. Really need to count common terms that are not badwords.\n    // TODO: fix matcher to not return trailing garbage. Example:\n    //   query: 'large and add a Petaluma Chicken'\n    //   prefix: 'large sprite;\n    //   match: 'large and' instead of 'large'\n    //\n    // const nonBadWordCount = match.reduce((count, term) => {\n    //     if (this.hashedBadWordsSet.has(term)) {\n    //         return count;\n    //     }\n    //     else {\n    //         return count + 1;\n    //     }\n    // }, 0);\n    // const badWordFactor = nonBadWordCount / match.length;\n    const commonTerms = this.commonTerms(query, prefix);\n    const commonBadWords = this.commonBadWords(commonTerms);\n\n    let score = matchFactor * commonFactor * positionFactor * lengthFactor;\n    // if (nonBadWordCount === 0) {\n    //     score = -1;\n    // }\n\n    // Exclude matches that are all badwords, except those that match every word\n    // in the prefix. As long as \"Fried\" and \"Fries\" stem to the same word, this\n    // prevents a collision between the entity, \"Fries\" and the attribute,\n    // \"Fried\". Using a lemmatizer instead of a stemmer could also help here.\n    const badWordFactor =\n        (commonTerms.size - commonBadWords.size) / commonTerms.size;\n    if (commonTerms.size === commonBadWords.size &&\n        commonTerms.size !== prefix.length) {\n      score = -1;\n    }\n\n    // if (score <= 0.25) {\n    //     score = -1;\n    // }\n    if (score <= 0.01) {\n      score = -1;\n    }\n\n    if (this.debugMode) {\n      const queryText = query.map(this.decodeTerm).join(' ');\n      const prefixText = prefix.map(this.decodeTerm).join(' ');\n      const matchText = match.map(this.decodeTerm).join(' ');\n      console.log(\n          `      score=${score} mf=${matchFactor}, cf=${commonFactor}, pf=${\n              positionFactor}, lf=${lengthFactor}, ff=${badWordFactor}`);\n      console.log(`      length=${match.length}, cost=${cost}, left=${\n          leftmostA}, right=${rightmostA}`);\n      console.log(`      query=\"${queryText}\"`);\n      console.log(`      prefix=\"${prefixText}\"`);\n      console.log(`      match=\"${matchText}\"`);\n      console.log(`      query=\"${query}\"`);\n      console.log(`      prefix=\"${prefix}\"`);\n      console.log(`      match=\"${match}\"`);\n      console.log();\n    }\n\n    return {score, length: rightmostA + 1};\n  }\n\n  // TODO: pass formatters here?\n  // TODO: return terms and path, instead of strings?\n  processQuery(query: string): Edge[] {\n    const terms = query.split(' ');\n    const stemmed = terms.map(this.stemTerm);\n    const hashed = stemmed.map(this.hashTerm);\n\n    // const edgeLists: Array<Array<{ score: number, length: number }>> = [];\n    const edgeLists: Edge[][] = [];\n    hashed.forEach((hash, index) => {\n      // TODO: exclude starting at hashes that are conjunctions.\n\n      if (hash in this.postings) {\n        // This query term is in at least one product term.\n        if (this.debugMode) {\n          const stemmedText = stemmed.slice(index).join(' ');\n          console.log(`  \"${stemmedText}\" SCORING:`);\n        }\n\n        // Get all of the items containing this query term.\n        // Items not containing this term will match better\n        // at other starting positions.\n        const items = this.postings[hash];\n\n        // Generate score for all of the items, matched against\n        // the tail of the query.\n        const tail = hashed.slice(index);\n        const scored = items.map(\n            (item) =>\n                ({...this.score(tail, this.hashedItems[item]), label: item}));\n\n        const sorted = scored.sort((a, b) => b.score - a.score);\n\n        edgeLists.push(sorted);\n      } else {\n        if (this.debugMode) {\n          console.log(`  \"${stemmed[index]}\" UNKNOWN`);\n        }\n        edgeLists.push([]);\n      }\n    });\n\n    const path = findBestPath(edgeLists);\n\n    if (this.debugMode) {\n      console.log('edge list:');\n      edgeLists.forEach((edges) => {\n        const text = edges.map(this.decodeEdge).join(',');\n        // const text = edges.map((edge) => `Edge(s=${edge.score},\n        // l=${edge.length})`).join(', ');\n        console.log(`    [${text}]`);\n      });\n      console.log('best path:');\n      path.forEach((edge) => {\n        console.log(`    ${this.decodeEdge(edge)}`);\n      });\n    }\n\n    return path;\n  }\n}\n"]}